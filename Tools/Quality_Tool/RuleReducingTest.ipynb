{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c1a43a",
   "metadata": {},
   "source": [
    "# Post-Hoc Rule Optimization: Merging & Pruning\n",
    "\n",
    "**Objective:**\n",
    "After extracting the initial set of decision rules for **CCF detection**, our goal is to simplify the model without significantly sacrificing performance (specifically **Recall**). We apply a two-stage optimization process:\n",
    "\n",
    "1.  **Rule Merging (Pairwise Analysis):**\n",
    "    We iteratively test merging every possible pair of rules (by identifying their common logical ancestors). This helps us find broader, more generalized rules that can replace specific variations.\n",
    "\n",
    "2.  **Rule Pruning (Leave-One-Out Test):**\n",
    "    We perform a sensitivity analysis to identify **redundant rules**. By removing one rule at a time and observing the drop in Recall, we can distinguish between \"critical rules\" (must-haves) and \"optional rules\" (safe to remove)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f50140",
   "metadata": {},
   "source": [
    "Software Lab 2025 Group 25\n",
    "\n",
    "File made by:  Nien-Ying Lin (03803153)\n",
    "go57vov@tum.de\n",
    "\n",
    "Documentation made by: Nien-Ying Lin (03803153) and Eduardo Silva (03805057)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e51140",
   "metadata": {},
   "source": [
    "### Environment & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6e396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# ===================== Configuration =====================\n",
    "BASE_DIR = Path.cwd()\n",
    "# get dataset file path\n",
    "DATA_PATH = BASE_DIR.parent.parent / \"Dataset/XAI_Drilling_Dataset.csv\"\n",
    "TARGET     = \"CCF\"  # Target variable for classification\n",
    "SPLIT_SEED = 259  # Random seed for train-test split\n",
    "TEST_SIZE  = 0.20  # Proportion of data to use for testing\n",
    "# =========================================================\n",
    "\n",
    "# Column Mapping: Standardize column names in dataset\n",
    "CANONICAL_MAP = {\n",
    "    \"Cutting_speed\":   [\"Cutting_speed\", \"Cutting speed vc [m/min]\"],\n",
    "    \"Spindle_speed\":   [\"Spindle_speed\", \"Spindle speed n [1/min]\"],\n",
    "    \"Feed_f\":          [\"Feed_f\", \"Feed f [mm/rev]\"],\n",
    "    \"Feed_rate\":       [\"Feed_rate\", \"Feed rate vf [mm/min]\"],\n",
    "    \"Power_Pc\":        [\"Power_Pc\", \"Power Pc [kW]\"],\n",
    "    \"Cooling\":         [\"Cooling\", \"Cooling [%]\"],\n",
    "    \"Material\":        [\"Material\"],\n",
    "    \"Drill_Bit_Type\":  [\"Drill_Bit_Type\", \"Drill Bit Type\"],\n",
    "    \"Process_Time\":    [\"Process_Time\", \"Process Time [sec]\"],\n",
    "    \"BEF\": [\"BEF\"], \"CCF\": [\"CCF\"], \"FWF\": [\"FWF\"], \"WDF\": [\"WDF\"]\n",
    "}\n",
    "\n",
    "# Safely retrieves a column from the DataFrame given a list of possible column names\n",
    "def _safe_get(df, variants):\n",
    "    for c in variants:\n",
    "        if c in df.columns: return df[c]\n",
    "    raise KeyError(f\"Missing columns: {variants}\")\n",
    "\n",
    "# Load the dataset and standardize column names based on the canonical map\n",
    "def load_dataset(path):\n",
    "    df0 = pd.read_csv(path)  # Read CSV into DataFrame\n",
    "    df = pd.DataFrame()  # New DataFrame to store canonicalized columns\n",
    "    for canon, variants in CANONICAL_MAP.items():\n",
    "        try: df[canon] = _safe_get(df0, variants)  # Standardize column names\n",
    "        except KeyError: pass\n",
    "    return df\n",
    "\n",
    "# Prepare features and target for model training\n",
    "def prepare_features(df, target):\n",
    "    # List of base columns to use for training\n",
    "    base_cols = [\"Cutting_speed\", \"Spindle_speed\", \"Feed_f\", \"Feed_rate\", \"Power_Pc\", \"Cooling\", \"Process_Time\", \"Material\", \"Drill_Bit_Type\"]\n",
    "    use_cols = [c for c in base_cols if c in df.columns]  # Select columns present in DataFrame\n",
    "    X = df[use_cols].copy()  # Features (independent variables)\n",
    "    y = df[target].astype(int).copy()  # Target (dependent variable)\n",
    "\n",
    "    # Numeric Cleaning: Convert to numeric and fill missing values with the median\n",
    "    for c in [\"Cutting_speed\", \"Spindle_speed\", \"Feed_f\", \"Feed_rate\", \"Power_Pc\", \"Cooling\", \"Process_Time\"]:\n",
    "        if c in X.columns:\n",
    "            X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(X[c].median())\n",
    "\n",
    "    # Categorical Encoding: Convert categorical columns to numeric codes\n",
    "    for c in [\"Material\", \"Drill_Bit_Type\"]:\n",
    "        if c in X.columns:\n",
    "            X[c + \"_enc\"] = X[c].astype(\"category\").cat.codes\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c628120",
   "metadata": {},
   "source": [
    "### Logic Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1db239",
   "metadata": {},
   "source": [
    "To perform precise merging operations, we decompose the rule logic into **\"Atoms\"**.\n",
    "\n",
    "* **Atoms:** The fundamental building blocks of our rules.\n",
    "* **Rule Construction:** Each rule is defined as a specific combination of these atoms.\n",
    "* **Input Configuration:**\n",
    "    We define the **baseline set of rules** to be analyzed in this experiment.\n",
    "    *(Note: The number of rules and their specific conditions below can be updated to reflect any rule setâ€”whether extracted directly from a tree or pre-simplified in a previous step.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170d2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define atomic conditions and rule structures manually for precise control over boundaries\n",
    "def get_rule_structs(X):\n",
    "    \"\"\"\n",
    "    Defines the exact atomic conditions and rule structures.\n",
    "    This manual definition allows for precise control over rule boundaries.\n",
    "    \"\"\"\n",
    "    # Feature shortcuts for easier access\n",
    "    C  = X[\"Cooling\"]\n",
    "    FR = X[\"Feed_rate\"]\n",
    "    P  = X[\"Power_Pc\"]\n",
    "    DB = X[\"Drill_Bit_Type_enc\"]\n",
    "    CS = X[\"Cutting_speed\"]\n",
    "    MT = X[\"Material_enc\"]\n",
    "    Ff = X[\"Feed_f\"]\n",
    "    PT = X[\"Process_Time\"]\n",
    "\n",
    "    # 1. Define Atoms (The Building Blocks) - basic conditions for each feature\n",
    "    atom_masks = {\n",
    "        \"C<=37.50\":   (C <= 37.50), \"C>37.50\":    (C > 37.50), \"C>62.50\":    (C > 62.50),\n",
    "        \"FR>62.50\":   (FR > 62.50), \"FR>70.50\":   (FR > 70.50),\n",
    "        \"FR>124.50\":  (FR > 124.50), \"FR>125.50\":  (FR > 125.50), \"FR<=124.50\": (FR <= 124.50),\n",
    "        \"FR>205.50\":  (FR > 205.50), \"FR>206.50\":  (FR > 206.50), \"FR<=205.50\": (FR <= 205.50),\n",
    "        \"P>63.52\":    (P > 63.52), \"P>64.54\":    (P > 64.54), \"P<=64.54\":   (P <= 64.54),\n",
    "        \"DB<=1.50\":   (DB <= 1.50), \"DB>1.50\":    (DB > 1.50), \"DB<=0.50\":   (DB <= 0.50), \"DB>0.50\":    (DB > 0.50),\n",
    "        \"CS>16.80\":   (CS > 16.80), \"CS<=16.80\":  (CS <= 16.80), \"CS<=17.03\":  (CS <= 17.03),\n",
    "        \"MT>1.00\":    (MT > 1.00),\n",
    "        \"Ff>0.20\":    (Ff > 0.20), \"Ff<=0.28\":   (Ff <= 0.28),\n",
    "        \"PT>35.10\":   (PT > 35.10), \"PT>35.34\":   (PT > 35.34),\n",
    "    }\n",
    "\n",
    "    # 2. Define The 8 Rules (Composed of Atoms) - Logical rules for classification\n",
    "    # Rule 1 is a special merged group (1+5+8 from original tree)\n",
    "    rule_atoms = {\n",
    "        1: [\"C<=37.50\", \"FR>124.50\", \"P>63.52\"],\n",
    "        2: [\"C>37.50\", \"FR>205.50\", \"FR>206.50\", \"DB<=1.50\"],\n",
    "        3: [\"C<=37.50\", \"FR<=124.50\", \"DB>1.50\"],\n",
    "        4: [\"C<=37.50\", \"FR<=124.50\", \"DB<=1.50\", \"FR>62.50\", \"FR>70.50\", \"CS>16.80\", \"DB<=0.50\", \"MT>1.00\"],\n",
    "        5: [\"C<=37.50\", \"FR<=124.50\", \"DB<=1.50\", \"FR>62.50\", \"FR>70.50\", \"CS<=16.80\", \"DB>0.50\"],\n",
    "        6: [\"C<=37.50\", \"FR<=124.50\", \"DB<=1.50\", \"FR>62.50\", \"FR>70.50\", \"CS>16.80\", \"DB>0.50\", \"Ff>0.20\"],\n",
    "        7: [\"C>37.50\", \"FR<=205.50\", \"Ff<=0.28\", \"PT>35.10\", \"DB<=1.50\", \"DB<=0.50\", \"C>62.50\"],\n",
    "        8: [\"C>37.50\", \"FR<=205.50\", \"Ff<=0.28\", \"PT>35.10\", \"DB>1.50\", \"Ff>0.20\"],\n",
    "    }\n",
    "\n",
    "    # Generate Masks for each rule based on atomic conditions\n",
    "    new_masks = {}\n",
    "    for idx, atoms in rule_atoms.items():\n",
    "        m = np.ones(len(X), dtype=bool)  # Start with all True values\n",
    "        for a in atoms:  # Apply all conditions for the rule\n",
    "            m = m & atom_masks[a]\n",
    "        new_masks[idx] = m\n",
    "        \n",
    "    orig_masks = {}\n",
    "    \n",
    "    return new_masks, atom_masks, rule_atoms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5df16f",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d5fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate the performance of a configuration\n",
    "def evaluate_config(name, y_te, mask_bool):\n",
    "    y_pred = mask_bool.astype(int)  # Convert boolean mask to binary predictions\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    cm = confusion_matrix(y_te, y_pred)  # Confusion matrix\n",
    "    p = precision_score(y_te, y_pred, zero_division=0)\n",
    "    r = recall_score(y_te, y_pred, zero_division=0)\n",
    "    f = f1_score(y_te, y_pred, zero_division=0)\n",
    "    \n",
    "    # Count missed failures\n",
    "    missed = (y_te.values == 1) & (y_pred == 0)\n",
    "    n_missed = missed.sum()\n",
    "    \n",
    "    return {\n",
    "        \"Configuration\": name,\n",
    "        \"Precision\": p,\n",
    "        \"Recall\": r,\n",
    "        \"F1\": f,\n",
    "        \"Missed_Failures\": n_missed\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5bb433",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d5343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Size: 4000 | Failures in Test: 69\n",
      "Running pairwise merge analysis...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuration</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Missed_Failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (Rules 1-8)</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merge R7 + R8</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.242531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Merge R5 + R6</td>\n",
       "      <td>0.130930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.231544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merge R4 + R6</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.160093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merge R4 + R5</td>\n",
       "      <td>0.084044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merge R3 + R4</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merge R3 + R5</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merge R3 + R6</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Merge R1 + R3</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Merge R1 + R4</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Configuration  Precision  Recall        F1  Missed_Failures\n",
       "0  Baseline (Rules 1-8)   0.958333     1.0  0.978723                0\n",
       "1         Merge R7 + R8   0.138000     1.0  0.242531                0\n",
       "2         Merge R5 + R6   0.130930     1.0  0.231544                0\n",
       "3         Merge R4 + R6   0.087011     1.0  0.160093                0\n",
       "4         Merge R4 + R5   0.084044     1.0  0.155056                0\n",
       "5         Merge R3 + R4   0.083942     1.0  0.154882                0\n",
       "6         Merge R3 + R5   0.083942     1.0  0.154882                0\n",
       "7         Merge R3 + R6   0.083942     1.0  0.154882                0\n",
       "8         Merge R1 + R3   0.083738     1.0  0.154535                0\n",
       "9         Merge R1 + R4   0.083738     1.0  0.154535                0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Strategy: Baseline (Rules 1-8)\n",
      "Recall: 1.000 (Missed: 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load Data\n",
    "df = load_dataset(DATA_PATH)  # Load dataset\n",
    "X, y = prepare_features(df, TARGET)  # Prepare features and target\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=TEST_SIZE, stratify=y, random_state=SPLIT_SEED)  # Train-test split\n",
    "\n",
    "print(f\"Test Set Size: {len(X_te)} | Failures in Test: {y_te.sum()}\")\n",
    "\n",
    "# 2. Get Rules\n",
    "new_masks, atom_masks, rule_atoms = get_rule_structs(X_te)  # Get rule structures\n",
    "results = []\n",
    "\n",
    "# --- Baseline: All 8 Rules Active ---\n",
    "mask_all8 = np.zeros(len(X_te), dtype=bool)  # Start with all False (no rules active)\n",
    "for idx in range(1, 9):\n",
    "    mask_all8 |= new_masks[idx]  # Combine all rule masks\n",
    "results.append(evaluate_config(\"Baseline (Rules 1-8)\", y_te, mask_all8))\n",
    "\n",
    "# --- Pairwise Merge Loop ---\n",
    "print(\"Running pairwise merge analysis...\")\n",
    "# Try merging each pair of rules and evaluate performance\n",
    "for i in range(1, 9):\n",
    "    for j in range(i+1, 9):\n",
    "        shared = set(rule_atoms[i]) & set(rule_atoms[j])  # Find shared conditions\n",
    "        \n",
    "        if len(shared) == 0:\n",
    "            parent_mask = np.ones(len(X_te), dtype=bool)  # No shared conditions, use all samples\n",
    "        else:\n",
    "            parent_mask = np.ones(len(X_te), dtype=bool)\n",
    "            for a in shared:\n",
    "                parent_mask &= atom_masks[a]  # Apply shared conditions\n",
    "        \n",
    "        merged_mask = parent_mask.copy()  # Copy the parent mask\n",
    "        for k in range(1, 9):  # Add all other rules not in the pair\n",
    "            if k != i and k != j:\n",
    "                merged_mask |= new_masks[k]\n",
    "        \n",
    "        # Record evaluation results\n",
    "        results.append(evaluate_config(f\"Merge R{i} + R{j}\", y_te, merged_mask))\n",
    "\n",
    "# 3. Summary Table: Sort results by F1 and Recall to find the best configurations\n",
    "df_res = pd.DataFrame(results)\n",
    "df_res = df_res.sort_values(by=[\"F1\", \"Recall\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 10 results\n",
    "display(df_res.head(10))\n",
    "\n",
    "best = df_res.iloc[0]\n",
    "print(f\"\\nBest Strategy: {best['Configuration']}\")\n",
    "print(f\"Recall: {best['Recall']:.3f} (Missed: {best['Missed_Failures']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0a2bc",
   "metadata": {},
   "source": [
    "## Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46df9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Leave-One-Out Test on 8 Rules...\n",
      "\n",
      "=== Elimination Results (Sorted by Recall Impact) ===\n",
      "Lower Recall = This rule was CRITICAL (Dropping it hurt performance)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Configuration</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Missed_Failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop Rule 1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drop Rule 2</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drop Rule 3</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drop Rule 4</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drop Rule 7</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drop Rule 5</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drop Rule 6</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drop Rule 8</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline (Keep All 8)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Configuration    Recall  Precision        F1  Missed_Failures\n",
       "0            Drop Rule 1  0.333333   0.958333  0.494624               46\n",
       "1            Drop Rule 2  0.855072   0.951613  0.900763               10\n",
       "2            Drop Rule 3  0.913043   0.954545  0.933333                6\n",
       "3            Drop Rule 4  0.956522   0.956522  0.956522                3\n",
       "4            Drop Rule 7  0.985507   0.971429  0.978417                1\n",
       "5            Drop Rule 5  0.985507   0.957746  0.971429                1\n",
       "6            Drop Rule 6  0.985507   0.957746  0.971429                1\n",
       "7            Drop Rule 8  0.985507   0.957746  0.971429                1\n",
       "8  Baseline (Keep All 8)  1.000000   0.958333  0.978723                0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Reuse the rules defined in the previous step\n",
    "# Assuming 'new_masks' and 'y_te' are available from the cells above\n",
    "\n",
    "results_drop = []  # List to store results for drop-one analysis\n",
    "target_rules = list(range(1, 9))  # List of rules to test dropping\n",
    "\n",
    "print(f\"Running Leave-One-Out Test on 8 Rules...\")\n",
    "\n",
    "# Baseline: Keep all 8 rules\n",
    "mask_all8 = np.zeros(len(X_te), dtype=bool)\n",
    "for r in target_rules:\n",
    "    mask_all8 |= new_masks[r]\n",
    "results_drop.append(evaluate_config(\"Baseline (Keep All 8)\", y_te, mask_all8))\n",
    "\n",
    "# Drop-One Loop: Test dropping each rule and measure impact on performance\n",
    "for drop_id in target_rules:\n",
    "    current_mask = np.zeros(len(X_te), dtype=bool)\n",
    "    kept_list = []\n",
    "    \n",
    "    for r in target_rules:\n",
    "        if r != drop_id:\n",
    "            current_mask |= new_masks[r]  # Add all rules except the dropped one\n",
    "            kept_list.append(r)\n",
    "            \n",
    "    # Record result\n",
    "    name = f\"Drop Rule {drop_id}\"\n",
    "    res = evaluate_config(name, y_te, current_mask)\n",
    "    res[\"Kept_Rules\"] = str(kept_list)  # List the rules that were kept\n",
    "    results_drop.append(res)\n",
    "\n",
    "# Create DataFrame for drop-one results\n",
    "df_drop = pd.DataFrame(results_drop)\n",
    "\n",
    "# Sort by Recall (ascending) and F1 (descending)\n",
    "df_drop = df_drop.sort_values(by=[\"Recall\", \"F1\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# Display results of dropping rules based on Recall impact\n",
    "print(\"\\n=== Elimination Results (Sorted by Recall Impact) ===\")\n",
    "print(\"Lower Recall = This rule was CRITICAL (Dropping it hurt performance)\")\n",
    "display(df_drop[[\"Configuration\", \"Recall\", \"Precision\", \"F1\", \"Missed_Failures\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-siemens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
