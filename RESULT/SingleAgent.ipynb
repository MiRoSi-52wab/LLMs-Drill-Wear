{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbceef3",
   "metadata": {},
   "source": [
    "# Single Agent Deployment Usage\n",
    "\n",
    "In this file we create a simple pipeline to use the Single Agent system with its best prompts. The techniques used for the prompt are explain inside the PromptEngineering/ folder. \n",
    "\n",
    "The goal is to just illustrate how the agentic system could be used in a simple manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2255369",
   "metadata": {},
   "source": [
    "Software Lab 2025 Group 25\n",
    "\n",
    "File made by: Eduardo Silva (03805057)\n",
    "eduardo.silva@tum.de\n",
    "\n",
    "Documentation made by: Eduardo Silva (03805057)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b77d0",
   "metadata": {},
   "source": [
    "# 1) Prompt For Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_AGENT_PROMPT = \"\"\"\n",
    "\n",
    "You have several tools at your disposal. When needed, please use themm to respond to the user's query.\n",
    "You need to think step by step, such as:\n",
    "    1) Evaluate what tools are necessary.\n",
    "    2) Check if all the values are given by the user.\n",
    "    3) Respond after obtaining the final response.\n",
    "\n",
    "If the user gives values in another units, you need to convert them into the right units used by the tools. \n",
    "Additionally, if there is some value missing, please tell the user that and refrain from calculating without this value.\n",
    "\n",
    "Lastly, make sure that you respond to all the user's questions and only if needed use both tools for the same answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599b70e",
   "metadata": {},
   "source": [
    "# 2) Create the Single Agent Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT CHANGE ANYTHING\n",
    "import json\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from Tools_LLM import get_wear, get_quality\n",
    "from langchain.agents import create_agent\n",
    "import time\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"granite3.3:2b\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "agent = create_agent(llm, tools=[get_wear, get_quality], system_prompt=SINGLE_AGENT_PROMPT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcc6c6",
   "metadata": {},
   "source": [
    "# 3) Talking to the Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the multi-agent system\n",
    "def chat_with_agents():\n",
    "    print(\"Welcome to the Single Agent System! Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Exit condition\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting the system. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Process the query through the supervisor agent\n",
    "        response = agent.invoke({\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
    "        })\n",
    "        \n",
    "        # Print the response\n",
    "        print(\"System:\", response[\"messages\"][-1].text)\n",
    "\n",
    "# Start the chat\n",
    "chat_with_agents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-siemens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
