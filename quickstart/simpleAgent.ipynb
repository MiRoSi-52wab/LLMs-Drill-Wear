{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41957fb",
   "metadata": {},
   "source": [
    "# Simple ReAct Agent (PreBuilt) With Tools Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5cb6ba",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0060fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276ebd1",
   "metadata": {},
   "source": [
    "Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649ccc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def estimate_wear(T_measured: float, T_sharp: float, beta: float) -> float:\n",
    "    \"\"\"\n",
    "    This tool allows you to estimate the wear on a drilling piece. \n",
    "\n",
    "    Please always use this tool when asked about wear of drill.\n",
    "    \"\"\"\n",
    "    W = (T_measured - T_sharp) / (beta * T_sharp)\n",
    "    return max(0.0, min(W, 1.0))\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def compute_sharp_torque(C2: float, R : float, f: float, w: float, p_deg:float, b:float) -> float:\n",
    "    \"\"\"\n",
    "    This tool allows you to estimate the torque of a drilling piece.\n",
    "\n",
    "    Always use this tool when asled about torque.\n",
    "    \"\"\"\n",
    "    p_rad = math.radians(p_deg)\n",
    "    sin2_p = math.sin(p_rad)**2\n",
    "\n",
    "    term1 = (C2 * (R**2) * f) / (b + 2)\n",
    "    term2 = C2 * f * (w**2) * sin2_p\n",
    "\n",
    "    return term1 + term2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33734b98",
   "metadata": {},
   "source": [
    "Example on How to invoke just the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f71ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(multiply.invoke({\"a\": 6, \"b\": 7}))  # returns 42\n",
    "\n",
    "print(estimate_wear.invoke({\"T_measured\": 1, \"T_sharp\": 0.5, \"beta\": 2}))\n",
    "# should return 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7feac",
   "metadata": {},
   "source": [
    "# Creating the Agent\n",
    "\n",
    "For this file, the default ReAct agent from langgraph is used.\n",
    "This because, initially we just want to have 1 LLM that accesses the tools. \n",
    "\n",
    "If Multi-Agent or Mixture of Experts is needed, then we will construct our own agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22c0f515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"what's 42 x 7?\", additional_kwargs={}, response_metadata={}, id='52221d30-931d-44b7-a484-0e3e7347b6db'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:30.674302889Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8314615578, 'load_duration': 17296586, 'prompt_eval_count': 387, 'prompt_eval_duration': 6861124931, 'eval_count': 22, 'eval_duration': 1434335466, 'model_name': 'llama3.2'}, id='run--485deb93-7ae7-4ea5-b3a0-e4a02fd4980c-0', tool_calls=[{'name': 'multiply', 'args': {'a': '42', 'b': '7'}, 'id': '2895d5fb-b41a-47aa-862b-3bdb6039009c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 387, 'output_tokens': 22, 'total_tokens': 409}), ToolMessage(content='294', name='multiply', id='202b2ac1-bde2-4026-a597-5f08e7f4f9a0', tool_call_id='2895d5fb-b41a-47aa-862b-3bdb6039009c'), AIMessage(content='The answer to the original question is: 42 × 7 = 294.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:32.695411605Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2000061416, 'load_duration': 16230776, 'prompt_eval_count': 95, 'prompt_eval_duration': 849981965, 'eval_count': 18, 'eval_duration': 1131439039, 'model_name': 'llama3.2'}, id='run--cd0409de-ff3f-4d17-aecb-978e9a1dd3f7-0', usage_metadata={'input_tokens': 95, 'output_tokens': 18, 'total_tokens': 113})]}\n",
      "{'messages': [HumanMessage(content='I want to estimate the wear of my model. I know that the value of T_meassured is 2.0, for T_sharp is 1.0 and for beta is 2.0', additional_kwargs={}, response_metadata={}, id='2507c843-6b1f-49d0-bc3e-45fe5c8a1c45'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:45.94083746Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9657020138, 'load_duration': 15237470, 'prompt_eval_count': 422, 'prompt_eval_duration': 7364643428, 'eval_count': 34, 'eval_duration': 2258307501, 'model_name': 'llama3.2'}, id='run--464d847a-bba8-48fe-b299-d69ec1baab22-0', tool_calls=[{'name': 'estimate_wear', 'args': {'T_measured': '2', 'T_sharp': '1', 'beta': '2'}, 'id': 'f569542d-d4b9-4d60-9b33-ec769302ac3c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 422, 'output_tokens': 34, 'total_tokens': 456}), ToolMessage(content='0.5', name='estimate_wear', id='6196b4fb-889b-45ed-8fcb-3474d4aa6e05', tool_call_id='f569542d-d4b9-4d60-9b33-ec769302ac3c'), AIMessage(content=\"The estimated wear of your model is approximately 0.5. This estimate is based on the provided values for T_measured, T_sharp, and beta.\\n\\nHere's a brief explanation of how this estimate was calculated:\\n\\n* The formula used to calculate the estimated wear is: Estimated Wear = (T_measured - T_sharp) / beta\\n* Plugging in the given values, we get: Estimated Wear = (2.0 - 1.0) / 2.0 = 0.5\\n\\nPlease note that this is a simplified estimate and actual wear may vary depending on various factors specific to your model.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:56.896172766Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10951044399, 'load_duration': 14743027, 'prompt_eval_count': 142, 'prompt_eval_duration': 1729304925, 'eval_count': 129, 'eval_duration': 9185593707, 'model_name': 'llama3.2'}, id='run--a53d9e78-7757-4b36-b574-f31d2ca3bcf3-0', usage_metadata={'input_tokens': 142, 'output_tokens': 129, 'total_tokens': 271})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "model = init_chat_model(\n",
    "    model_provider=\"ollama\",\n",
    "    model=\"llama3.2\",\n",
    "    temperature = 0,\n",
    ")\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[multiply, estimate_wear, compute_sharp_torque]\n",
    ")\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's 42 x 7?\"}]})\n",
    "print(response)\n",
    "response2 = agent.invoke({\"messages\": \n",
    "              [{\"role\": \"user\", \n",
    "                \"content\": \"I want to estimate the wear of my model. I know that the value of T_meassured is 2.0, for T_sharp is 1.0 and for beta is 2.0\"}\n",
    "                ]})\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b42fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"what's 42 x 7?\", additional_kwargs={}, response_metadata={}, id='52221d30-931d-44b7-a484-0e3e7347b6db'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:30.674302889Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8314615578, 'load_duration': 17296586, 'prompt_eval_count': 387, 'prompt_eval_duration': 6861124931, 'eval_count': 22, 'eval_duration': 1434335466, 'model_name': 'llama3.2'}, id='run--485deb93-7ae7-4ea5-b3a0-e4a02fd4980c-0', tool_calls=[{'name': 'multiply', 'args': {'a': '42', 'b': '7'}, 'id': '2895d5fb-b41a-47aa-862b-3bdb6039009c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 387, 'output_tokens': 22, 'total_tokens': 409}), ToolMessage(content='294', name='multiply', id='202b2ac1-bde2-4026-a597-5f08e7f4f9a0', tool_call_id='2895d5fb-b41a-47aa-862b-3bdb6039009c'), AIMessage(content='The answer to the original question is: 42 × 7 = 294.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:32.695411605Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2000061416, 'load_duration': 16230776, 'prompt_eval_count': 95, 'prompt_eval_duration': 849981965, 'eval_count': 18, 'eval_duration': 1131439039, 'model_name': 'llama3.2'}, id='run--cd0409de-ff3f-4d17-aecb-978e9a1dd3f7-0', usage_metadata={'input_tokens': 95, 'output_tokens': 18, 'total_tokens': 113})]\n",
      "content=\"what's 42 x 7?\" additional_kwargs={} response_metadata={} id='52221d30-931d-44b7-a484-0e3e7347b6db'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:30.674302889Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8314615578, 'load_duration': 17296586, 'prompt_eval_count': 387, 'prompt_eval_duration': 6861124931, 'eval_count': 22, 'eval_duration': 1434335466, 'model_name': 'llama3.2'} id='run--485deb93-7ae7-4ea5-b3a0-e4a02fd4980c-0' tool_calls=[{'name': 'multiply', 'args': {'a': '42', 'b': '7'}, 'id': '2895d5fb-b41a-47aa-862b-3bdb6039009c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 387, 'output_tokens': 22, 'total_tokens': 409}\n",
      "content='294' name='multiply' id='202b2ac1-bde2-4026-a597-5f08e7f4f9a0' tool_call_id='2895d5fb-b41a-47aa-862b-3bdb6039009c'\n",
      "content='The answer to the original question is: 42 × 7 = 294.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:32.695411605Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2000061416, 'load_duration': 16230776, 'prompt_eval_count': 95, 'prompt_eval_duration': 849981965, 'eval_count': 18, 'eval_duration': 1131439039, 'model_name': 'llama3.2'} id='run--cd0409de-ff3f-4d17-aecb-978e9a1dd3f7-0' usage_metadata={'input_tokens': 95, 'output_tokens': 18, 'total_tokens': 113}\n",
      "###\n",
      "content='I want to estimate the wear of my model. I know that the value of T_meassured is 2.0, for T_sharp is 1.0 and for beta is 2.0' additional_kwargs={} response_metadata={} id='2507c843-6b1f-49d0-bc3e-45fe5c8a1c45'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:45.94083746Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9657020138, 'load_duration': 15237470, 'prompt_eval_count': 422, 'prompt_eval_duration': 7364643428, 'eval_count': 34, 'eval_duration': 2258307501, 'model_name': 'llama3.2'} id='run--464d847a-bba8-48fe-b299-d69ec1baab22-0' tool_calls=[{'name': 'estimate_wear', 'args': {'T_measured': '2', 'T_sharp': '1', 'beta': '2'}, 'id': 'f569542d-d4b9-4d60-9b33-ec769302ac3c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 422, 'output_tokens': 34, 'total_tokens': 456}\n",
      "content='0.5' name='estimate_wear' id='6196b4fb-889b-45ed-8fcb-3474d4aa6e05' tool_call_id='f569542d-d4b9-4d60-9b33-ec769302ac3c'\n",
      "content=\"The estimated wear of your model is approximately 0.5. This estimate is based on the provided values for T_measured, T_sharp, and beta.\\n\\nHere's a brief explanation of how this estimate was calculated:\\n\\n* The formula used to calculate the estimated wear is: Estimated Wear = (T_measured - T_sharp) / beta\\n* Plugging in the given values, we get: Estimated Wear = (2.0 - 1.0) / 2.0 = 0.5\\n\\nPlease note that this is a simplified estimate and actual wear may vary depending on various factors specific to your model.\" additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-07-10T12:54:56.896172766Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10951044399, 'load_duration': 14743027, 'prompt_eval_count': 142, 'prompt_eval_duration': 1729304925, 'eval_count': 129, 'eval_duration': 9185593707, 'model_name': 'llama3.2'} id='run--a53d9e78-7757-4b36-b574-f31d2ca3bcf3-0' usage_metadata={'input_tokens': 142, 'output_tokens': 129, 'total_tokens': 271}\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'])\n",
    "for i in range(0, len(response['messages'])):\n",
    "    print(response['messages'][i])\n",
    "\n",
    "print(\"###\")\n",
    "for i in range(0, len(response2['messages'])):\n",
    "    print(response2['messages'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9020ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages\n",
      "User: What do you know about LangGraph?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m user_input = \u001b[33m\"\u001b[39m\u001b[33mWhat do you know about LangGraph?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUser: \u001b[39m\u001b[33m\"\u001b[39m + user_input)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mstream_graph_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mstream_graph_updates\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream_graph_updates\u001b[39m(user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event)\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event.values():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/pregel/runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/utils/runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/utils/runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langgraph/prebuilt/chat_agent_executor.py:505\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.call_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) -> StateSchema:\n\u001b[32m    504\u001b[39m     state = _get_model_input_state(state)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     response = cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    506\u001b[39m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    507\u001b[39m     response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = context.run(step.invoke, input_, config)\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_ollama/chat_models.py:741\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    736\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    739\u001b[39m     **kwargs: Any,\n\u001b[32m    740\u001b[39m ) -> ChatResult:\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    744\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m    745\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    746\u001b[39m         message=AIMessage(\n\u001b[32m    747\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    752\u001b[39m         generation_info=generation_info,\n\u001b[32m    753\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_ollama/chat_models.py:678\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    670\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    671\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    675\u001b[39m     **kwargs: Any,\n\u001b[32m    676\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    677\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_ollama/chat_models.py:763\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m    757\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    758\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m    759\u001b[39m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m    762\u001b[39m     is_thinking = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/langchain_ollama/chat_models.py:665\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    662\u001b[39m chat_params = \u001b[38;5;28mself\u001b[39m._chat_params(messages, stop, **kwargs)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/ollama/_client.py:172\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    169\u001b[39m   e.response.read()\n\u001b[32m    170\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpx/_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpx/_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/sl-siemens/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        print(event)\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-siemens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
