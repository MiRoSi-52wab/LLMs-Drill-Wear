{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2047a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16429a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply.invoke({\"a\": 6, \"b\": 7})  # returns 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e9e4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def estimate_wear(T_measured: float, T_sharp: float, beta: float) -> float:\n",
    "    \"\"\"\n",
    "    This tool allows you to estimate the wear on a drilling piece. \n",
    "\n",
    "    Please always use this tool when asked about wear of drill.\n",
    "    \"\"\"\n",
    "    W = (T_measured - T_sharp) / (beta * T_sharp)\n",
    "    return max(0.0, min(W, 1.0))\n",
    "\n",
    "estimate_wear.invoke({\"T_measured\": 1, \"T_sharp\": 0.5, \"beta\": 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "148d56a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 42 x 7?\", additional_kwargs={}, response_metadata={}, id='d26104e3-8781-4482-a884-a97283f15b46'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-02T14:25:10.060258251Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12569449875, 'load_duration': 6762519940, 'prompt_eval_count': 167, 'prompt_eval_duration': 4262528839, 'eval_count': 22, 'eval_duration': 1517206158, 'model_name': 'llama3.2'}, id='run--8ee2ebc5-7a47-48f4-9b46-b5af1b4bee5f-0', tool_calls=[{'name': 'multiply', 'args': {'a': '42', 'b': '7'}, 'id': 'e3931679-179c-4ddf-80b9-4821cb7ba934', 'type': 'tool_call'}], usage_metadata={'input_tokens': 167, 'output_tokens': 22, 'total_tokens': 189}),\n",
       "  ToolMessage(content='294', name='multiply', id='fb836846-f051-45bf-933a-2e7cda02ecfc', tool_call_id='e3931679-179c-4ddf-80b9-4821cb7ba934'),\n",
       "  AIMessage(content='The result of multiplying 42 by 7 is 294.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-07-02T14:25:12.078737664Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2008427823, 'load_duration': 50384602, 'prompt_eval_count': 95, 'prompt_eval_duration': 1016565333, 'eval_count': 14, 'eval_duration': 920548396, 'model_name': 'llama3.2'}, id='run--80f18732-4996-4b07-93af-71da031ff54e-0', usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"ollama:llama3.2\",\n",
    "    tools=[multiply]\n",
    ")\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's 42 x 7?\"}]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-siemens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
